- name: demo_robotatcwe
  id: 2
  image: demo_robotatcwe.png
  title: Robot@CWE
  lab: JRL-Japan
  description: This is the Final demonstrator of the FP7 IP Robot@CWE project.
  ref: stasse-robot-13
  video:
    youtube_id: hRf0XJaIlmY

- name: demo_ballerose
  id: 3
  image: demo_ballerose.png
  title: Grasping while walking
  lab: JRL-Japan
  description: Grasping a ball with visual guidance while walking. First demonstration with the presented framework during the end of Nicolas Mansard's PhD
  ref: mansard-icra-07
  url: http://www.irisa.fr/lagadic/publi/publi/Mansard07a-eng.html

- name: demo_frigo
  id: 10
  image: demo_frigo.png
  title: Open the fridge
  lab: JRL-Japan
  description: The robot opens a fridge to grasp a can. The motion results from an optimized task sequence. The motion was implemented by F. Keith during his PhD thesis.
  ref: keith-iros-09
  url: http://hal-lirmm.ccsd.cnrs.fr/lirmm-00733383

- name: demo_switch
  id: 4
  image: demo_switch.png
  title: Haptic communication
  lab: JRL-Japan
  description: Study about the haptic (non verbal) communication between two human partners during a task implying physical collaboration. The resulting strategies are applied to drive the humanoid robot decisions. The motion was programmed by A. Bussy during his PhD thesis.
  ref: bussy-iros-12
  video:
    youtube_id: kYUdYOIYeZ0
  url: http://hal-lirmm.ccsd.cnrs.fr/lirmm-00773403

- name: demo_bci
  id: 6
  image: demo_bci.png
  title: Brain computer interface
  lab: JRL-Japan
  description: The robot is driven by symbolic orders that are selected by a brain-computer interface. The orders are converted into tasks that are applied by the robot. The demonstration was developped by P. Gergondet during his PhD thesis. It is one of the main demonstrators of the FP7 IP VERE project.
  ref: gergondet-roma-12
  video:
    youtube_id: dyw4fz4VIU4
  url: http://hal-lirmm.ccsd.cnrs.fr/lirmm-00781528

- name: demo_torea_robot
  id: 7
  image: demo_torea_robot.png
  title: Active vision
  lab: JRL-Japan
  description: The robot autonomously selects the most relevant poses to improve the 3D reconstruction of an ob ject. The built model is then used for the "Treasure hunting" project, led by O. Stasse [Saidi 07]. The active-search movements have been develop ed by T. Foissote during his PhD thesis.
  ref: Foissotte:2010

- name: demo_joystick
  id: 8
  image: demo_joystick.png
  title: Joystick-controlled walk
  lab:
    - JRL-Japan
    - INRIA
  description: First application of the "joystick-drive" walking pattern generator. The COM tra jectory is the closest to the velo city input given by the joystick [Herdt 10]. The footprints are computed during the COM trajectory optimization and bounded to stay inside a security zone computed during a learning process [Stasse 09].
  ref: perrin-icra-10
  url: http://homepages.laas.fr/florent/publi/10icra.pdf



- name: demo_dune
  id: 9
  image: demo_dune.png
  title: Visual servoing of the walk
  lab: JRL-Japan
  description: Similarly to the previous item, the robot COM and footprints are computed by model-predictive control. This time, the robot velocity is input by the camera feedback, following a visual-servoing scheme.
  ref: dune10
  url: http://hal.inria.fr/inria-00567664

- name: demo_stpbv
  image: demo_stpbv.png
  title: Obstacle avoidance
  lab: JRL-Japan
  description: The obstacles are locally taken into account in the control scheme. The task used to prevent the collision is based on a smooth body envelope [Escande 07].
  ref: stasse-icra-08
  url: http://homepages.laas.fr/ostasse/os_icra_2008.pdf

- name: demo_skin
  id: 10
  image: demo_skin.png
  title: Skin for humanoid robots
  lab:
    - JRL-Japan
    - TUM
  description: Several tactile and proximetric sensor cells are attached to the HRP-2 robot cover. They are used to guide the robot and teach by showing how to grasp various classes of ob ject using whole-body grasps.
  ref: mittendorfer-iros-13
  url: hal.archives-ouvertes.fr/hal-00805079
  video:
    file_url: http://hal.archives-ouvertes.fr/docs/00/80/50/79/VIDEO/2013_A_General_Tactile_Approach_for_Grasping_Unknown_Objects_with_a_Humanoid_Robot.mp4

- name: demo_mexique
  id: 11
  image: demo_mexique.png
  title: Pursuit-evasion planning
  lab:
    - JRL-Japan
    - CIMAT
  description: A navigation trajectory is computed while taking into account the robot visibility constraints. The plan is then executed using the walking pattern generator and the proposed whole-body resolution scheme.
  ref: hayet-ijhr-12
  url: https://staff.aist.go.jp/e.yoshida/papers/hayet-ijhr12.pdf

- name: demo_clermont
  id: 12
  image: demo_clermont.png
  title: Bi-manual visual servoing
  lab:
    - LAAS
    - LASMEA
  description: The head and both arms are controlled following a 2D visual feedback.
  ref: moughlbay-jnrh-10

- name: demo_fastplan
  id: 13
  image: demo_fastplan.png
  title: Fast footstep replanning
  lab:
    - LAAS
    - JRL-Japan
  description: Using fast feasibility tests, the footsteps leading to a goal position are recomputed on the light to track modifications of the environment. The footstep plan is then executed by inverse kinematics
  ref: baudouin-humanoids-11
  url: http://hal.archives-ouvertes.fr/docs/00/60/13/00/PDF/humanoids11-lbaudouin.pdf
  video:
    youtube_id: H6cbwkNTafw

## - name: demo_kidroom
##   id: 14
##   image: demo_kidroom.png
##   title: Careful steps through a kidroom
##   lab: LAAS
##   description: A footstep plan is computed into a very constrained environment. The flying-foot position is servoed. A programming language during the execution based on visual feedback. The demonstration was realized by T. Moulard during his PhD thesis.
##   ref: moulard-biorob-12
##   url: http://hal.archives-ouvertes.fr/hal-00601291
##   video:
##     youtube_id: cUZ0nNiPs70

## - name: demo_novela
##   id: 15
##   image: demo_novela.png
##   title: Yoga dance
##   lab: LAAS
##   description: The robot motion is computed from motion-capture dynamic motion of a human dancer. Most of the work has been done by O. Ramos during his Master thesis.
##   ref: ramos-ram-sub13

## - name: demo_chair
##   id: 16
##   image: demo_chair.png
##   title: Stting into an armchair
##   lab: LAAS
##   description: The motion illustrates multi-contact capabilities of the generation algorithm. It is executed in op en loop by the robot. This motion was developed by L. Saab during her PhD thesis.
##   ref: saab-tro-12
##   url: http://hal-lirmm.ccsd.cnrs.fr/lirmm-00831097

## - name: demo_hak
##   id: 17
##   image: demo_hak.png
##   title: Motion recognition
##   lab:
##     - LAAS
##     - JRL-Japan
##   description: The task-function approach is used to describe an observed motion.
##   ref: hak-tsmc-12
##   url: http://hal.archives-ouvertes.fr/hal-00697272

## - name: demo_duong
##   id: 18
##   image: demo_duong.png
##   title: Visual footstep planning and control
##   lab: LAAS
##   description:
##   ref: duong-humanoid-12
##   url: hal.inria.fr/hal-00727600


## - name: demo_smallstep_cdf
##   id: 19
##   image: demo_smallstep_cdf.png
##   title: Small-step controllability
##   lab: LAAS
##   description: The framework is used to execute a footstep plan computed by homotopy [Kanoun 11b]. The footstep trajectory is computed at the medium rate of 3Hz. The footsteps and robot posture is then sent to the control and performed in real time. Both algorithm loops are closed on the camera feedback. This motion was developed by D. Dang during his PhD thesis.
##   ref: dalibard-humanoid-11
##   url: hal.inria.fr/hal-00602384



## - name: demo_slam
##   id: 20
##   image: demo_slam.png
##   title: SLAM based robot control
##   lab: LAAS
##   description: The robot localizes itself using a visual sparse map. The localization error is back fed to the control that corrects the position with respect to an input plan. The robot finally grasps a ball after several steps. The demonstration was developed by T. Moulard during his PhD thesis.
##   ref: moulard-icra-12sub
##   url: http://hal.inria.fr/hal-00733666
##   video:
##     file_url:http://hal.archives-ouvertes.fr/docs/00/73/36/66/VIDEO/13icra.mp4

## - name: demo_dyninv
##   id: 21
##   image: demo_dyninv.png
##   title: Climbing a ladder
##   lab: LAAS
##   description: Application of the multi-contact inverse-dynamics motion generation to the humanoid robot Romeo model.
##   ref: ramos-humanoid-11
##   url: hal.archives-ouvertes.fr/hal-00600959
##   video:
##     youtube_id: WkBU20Ut1Yo


## - name: demo_stab
##   id: 22
##   image: demo_stab.png
##   title: Balance stabilization
##   description:  Developments toward outdoor walking, by F. Lamiraux.
##   lab:
##     - LAAS


## - name: demo_theremin
##   id: 23
##   image: demo_theremin.png
##   title: Audio-based control
##   lab:
##     - LAAS
##     - SIPG Okuno Lab
##   description: Developments for the standing HRP-2 of an audio-based control, originally developed for a sitting HRP-2. The hand position is servoed to adjust the sound of the Theremin music instrument. The tempo is then adjusted by a conductor using the motion capture to track the baton.
##   ref: mizumoto-iros-09

## - name: demoros
##   id: 24
##   image: demoros.png
##   title: ROS bridge
##   lab: LAAS
##   description: The framework is bridged to the middleware ROS. The middleware is used to import data coming from other processes or other computers (vision data, user commands, etc). The PR-2 model is included in the framework.
##   ref: moulard-ros-12

## - name: demo_romeo
##   id: 25
##   image: demo_romeo.png
##   title: Navigation planning and execution
##   lab: INRIA
##   description: The robot Romeo navigates into a virtual home environment and finally performs a manipulation task. Final demonstrator of WP7 of the FUI Romeo project
##   ref: keith-wpromeo-11
##   video:
##     youtube_id: eiQctKGUPw4
